{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49d2d2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#as we have lot of methods to train our data like randomForestClassifier , logistic regression, linear regression,tree classifier, svm etc hence in order to know the best best method to train our data is tusing cross validation\n",
    "#new technique to train our model apart from train test split is KFold cross validation \n",
    "# in this we divide our sample into folds like if we have 100 samples then let one fold have 20 samples => 5 folds we will have\n",
    "# now we will train our model iterations wise like in first we use fold one for testing and remaining for training similarly in second 2nd for testing and remaining for training nd repeat this process\n",
    "# and finally we will take the average of all the accuracies we got in each iteration\n",
    "# this is a very good technique to train our model as it gives us the best accuracy and also helps us to avoid overfitting\n",
    "# we will use KFold cross validation to train our\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_digits\n",
    "digits=load_digits()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "086de906",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(digits.data,digits.target,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "064ea30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9638888888888889"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr=LogisticRegression()\n",
    "lr.fit(x_train,y_train)\n",
    "lr.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9abffd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9722222222222222"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm=SVC(kernel='linear')  # You can also try 'rbf', 'poly', etc.\n",
    "svm.fit(x_train,y_train)\n",
    "svm.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9ca122",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf=RandomForestClassifier(n_estimators=40)\n",
    "rf.fit(x_train,y_train)\n",
    "rf.score(x_test,y_test)\n",
    "#problem with these methods is that every time when we run the split the different data will be available for training and testing which changes the score of the model every time whenever we run the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20977cf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kf=KFold(n_splits=3) # n_splits is the number of folds you want to create\n",
    "kf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0b50f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 4 5 6 7 8] [0 1 2]\n",
      "[0 1 2 6 7 8] [3 4 5]\n",
      "[0 1 2 3 4 5] [6 7 8]\n"
     ]
    }
   ],
   "source": [
    "for train_index, test_index in kf.split([1,2,3,4,5,6,7,8,9]):\n",
    "    print(train_index, test_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71490679",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the generic function to calculate the score as per the method supplied\n",
    "def get_score(model,x_train,x_test,y_train,y_test):\n",
    "    model.fit(x_train,y_train)\n",
    "    return model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "727c83b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9638888888888889"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(LogisticRegression(),x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4b2f5b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9888888888888889"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(SVC(),x_train,x_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33cb7ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedKFold(n_splits=3, random_state=None, shuffle=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "#it is better than kFold b/c when we divide our folds it will divide it in a uniform way with proper classification category\n",
    "folds = StratifiedKFold(n_splits=3)\n",
    "folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c68ad967",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_1=[]\n",
    "scores_svm=[]\n",
    "scores_rf=[]\n",
    "\n",
    "for train_index, test_index in kf.split(digits.data):\n",
    "    x_train,x_test,y_train,y_test=digits.data[train_index],digits.data[test_index],digits.target[train_index],digits.target[test_index]\n",
    "    scores_1.append(get_score(LogisticRegression(),x_train,x_test,y_train,y_test))\n",
    "    scores_svm.append(get_score(SVC(),x_train,x_test,y_train,y_test))\n",
    "    scores_rf.append(get_score(RandomForestClassifier(n_estimators=40),x_train,x_test,y_train,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34b21d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9232053422370617, 0.9415692821368948, 0.9148580968280468]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e39f86f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9666110183639399, 0.9816360601001669, 0.9549248747913188]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b84b7ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9315525876460768, 0.9348914858096828, 0.9198664440734557]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b20c1777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.92222222, 0.86944444, 0.94150418, 0.93871866, 0.89693593])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(LogisticRegression(),digits.data,digits.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c27dcd2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.96111111, 0.94444444, 0.98328691, 0.98885794, 0.93871866])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(SVC(),digits.data,digits.target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
